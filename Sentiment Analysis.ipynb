# Import Required Libraries
import pandas as pd
import numpy as np
import nltk
import re
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score

# Importing Data
data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding = 'latin-1', header = None)
data.columns = ['sentiment','id','date','query','user','text']
data.head()

data.shape

data.isnull().sum()

data.duplicated().sum()

data['sentiment'].value_counts()

data = data[['sentiment', 'text']]
data['sentiment'] = data['sentiment'].apply(lambda x : 1 if x == 4 else 0)  # 1 = positive 0 = negative
data.head()

data['sentiment'].value_counts()

# Text Cleaning
def clean_text(text):
    text = re.sub(r"http\S+|www\S+|https\S+", '', text) # Remove URLs
    text = re.sub(r"@\w+", "", text)                    # Remove mentions
    text = text.lower()
    return text

data['clean_text'] = data['text'].apply(clean_text)
data.head()

# To create neutral sentiments
analyzer = SentimentIntensityAnalyzer()

def get_vader_label(text):
    score = analyzer.polarity_scores(text)['compound']
    if score >= 0.3:
        return "positive"
    elif score <= -0.3:
        return "negative"
    else:
        return "neutral"      

data['final_sentiment'] = data['clean_text'].apply(get_vader_label)

# Balance the Dataset
min_size = data["final_sentiment"].value_counts().min()
data_balanced = (
    data.groupby("final_sentiment", group_keys=False)
      .sample(min_size, random_state=42)
)

# Train Test Split
x_train, x_test, y_train, y_test = train_test_split(data_balanced["clean_text"], 
                                                    data_balanced["final_sentiment"], 
                                                    test_size = 0.2, random_state = 42, 
                                                   stratify=data_balanced["final_sentiment"])  

# Convert text -> Numbers
vectorizer = CountVectorizer(
    max_features=60000,
    ngram_range=(1, 2),
    stop_words="english"
)

x_train_vec = vectorizer.fit_transform(x_train)
x_test_vec = vectorizer.transform(x_test)

# Model Fitting
model = MultinomialNB(alpha= 0.3)
model.fit(x_train_vec, y_train)

# Prediction
y_pred = model.predict(x_test_vec)

# Calculate Accuracy
print(accuracy_score(y_test, y_pred))

# Predict sentiment for new text
def predict_sentiment(text):
    text = clean_text(text)
    vec = vectorizer.transform([text])
    return model.predict(vec)[0]

print(predict_sentiment("I absolutely love this product"))
print(predict_sentiment("This phone is okay, nothing special"))
print(predict_sentiment("Worst experience ever"))

print(predict_sentiment("This phone is okay and works as expected"))

print(predict_sentiment("The product arrived on time and matches the description."))

print(predict_sentiment("It does what it is supposed to do."))

print(predict_sentiment("The experience was average, nothing unusual."))

print(predict_sentiment("I have been using it for a few days without any issues."))
